{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to vitm This project aims to recreate the vision-transformers from the hugging face vison models, the project contains many helpful functions, classes and scripts, which could be reused to train your own Vision Transformer.","title":"Home"},{"location":"#welcome-to-vitm","text":"This project aims to recreate the vision-transformers from the hugging face vison models, the project contains many helpful functions, classes and scripts, which could be reused to train your own Vision Transformer.","title":"Welcome to vitm"},{"location":"utils/loadData/","text":"loadData Load the CIFAR-10 dataset with optional resizing and return a DataLoader. Parameters: batch_size ( int , default: 32 ) \u2013 Number of samples per batch. resize ( int , default: 0 ) \u2013 If non-zero, resizes image to (resize, resize). Returns: image_size ( Tuple [ int , int ] ) \u2013 Width and height of the images. num_classes ( int ) \u2013 Number of classes in the dataset. trainloader ( DataLoader ) \u2013 PyTorch DataLoader with training data. Source code in vitm/data/dataloader.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def loadData ( batch_size : int = 32 , resize : int = 0 ): \"\"\" Load the CIFAR-10 dataset with optional resizing and return a DataLoader. Args: batch_size (int): Number of samples per batch. resize (int): If non-zero, resizes image to (resize, resize). Returns: image_size (Tuple[int, int]): Width and height of the images. num_classes (int): Number of classes in the dataset. trainloader (DataLoader): PyTorch DataLoader with training data. \"\"\" compose_arg = [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 )) ] if resize != 0 : compose_arg . insert ( 0 , transforms . Resize ( resize ),) transform = transforms . Compose ( compose_arg ) # Take the dataset name through the CLI and check if the dataset is available or not? # If the dataset has to be taken from other resources then - clean it first trainset = torchvision . datasets . CIFAR10 ( root = './data' , train = True , download = True , transform = transform ) subset_indices = random . sample ( range ( len ( trainset )), 50000 ) train_subset = Subset ( trainset , subset_indices ) trainloader = torch . utils . data . DataLoader ( train_subset , batch_size = batch_size , shuffle = True , num_workers = 2 , # num_workers needs to be tuned pin_memory = True ) classes = ( 'plane' , 'car' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck' ) # making a vision transformer model data_iter = iter ( trainloader ) images , labels = next ( data_iter ) num_classes = len ( classes ) image_shape = images [ 0 ] . shape image_size = image_shape [ - 2 ], image_shape [ - 1 ] print ( \"DATA INFO:\" ) print ( \"# Samples:\" , len ( trainloader . dataset )) print ( \"# Classes:\" , len ( classes )) print ( \"Image size:\" , image_size ) return image_size , num_classes , trainloader from vitm.data.dataloader import loadData image_size, num_classes, trainloader = loadData(batch_size=64, resize=224)","title":"loadData"},{"location":"utils/loadData/#loaddata","text":"Load the CIFAR-10 dataset with optional resizing and return a DataLoader. Parameters: batch_size ( int , default: 32 ) \u2013 Number of samples per batch. resize ( int , default: 0 ) \u2013 If non-zero, resizes image to (resize, resize). Returns: image_size ( Tuple [ int , int ] ) \u2013 Width and height of the images. num_classes ( int ) \u2013 Number of classes in the dataset. trainloader ( DataLoader ) \u2013 PyTorch DataLoader with training data. Source code in vitm/data/dataloader.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def loadData ( batch_size : int = 32 , resize : int = 0 ): \"\"\" Load the CIFAR-10 dataset with optional resizing and return a DataLoader. Args: batch_size (int): Number of samples per batch. resize (int): If non-zero, resizes image to (resize, resize). Returns: image_size (Tuple[int, int]): Width and height of the images. num_classes (int): Number of classes in the dataset. trainloader (DataLoader): PyTorch DataLoader with training data. \"\"\" compose_arg = [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 )) ] if resize != 0 : compose_arg . insert ( 0 , transforms . Resize ( resize ),) transform = transforms . Compose ( compose_arg ) # Take the dataset name through the CLI and check if the dataset is available or not? # If the dataset has to be taken from other resources then - clean it first trainset = torchvision . datasets . CIFAR10 ( root = './data' , train = True , download = True , transform = transform ) subset_indices = random . sample ( range ( len ( trainset )), 50000 ) train_subset = Subset ( trainset , subset_indices ) trainloader = torch . utils . data . DataLoader ( train_subset , batch_size = batch_size , shuffle = True , num_workers = 2 , # num_workers needs to be tuned pin_memory = True ) classes = ( 'plane' , 'car' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck' ) # making a vision transformer model data_iter = iter ( trainloader ) images , labels = next ( data_iter ) num_classes = len ( classes ) image_shape = images [ 0 ] . shape image_size = image_shape [ - 2 ], image_shape [ - 1 ] print ( \"DATA INFO:\" ) print ( \"# Samples:\" , len ( trainloader . dataset )) print ( \"# Classes:\" , len ( classes )) print ( \"Image size:\" , image_size ) return image_size , num_classes , trainloader from vitm.data.dataloader import loadData image_size, num_classes, trainloader = loadData(batch_size=64, resize=224)","title":"loadData"}]}